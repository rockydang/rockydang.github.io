---
layout:     post
title:      浅谈HashMap
subtitle:   
date:       2018-02-25
author:     rockybobo
header-img: img/myname/post_20170212_01.jpg
catalog: true
tags:
    - 技术
---

## 浅谈HashMap

 #### HashMap的数据结构

~~~
1、众所周知，HashMap是一个key-value键值对集合，每一个键值对也叫做一个Entry 
这个键值对(Entry)分散存储在一个数组当中，这个数组就是HashMap的主干；
2、采用头插法的原因是：HashMap的发明者认为，后插入的Entry被查找的可能性更大。
   而且插入的效率比较高，当新来的Entry映射到冲突的数组位置时，只需要插入到对应的链表即可：
   HashMap数组的每一个元素不止是一个Entry对象，也是一个链表的头节点。每一个Entry对象通过Next指针指向它的
   下一个Entry节点。
~~~

#### HashMap的默认长多少？为什么这样规定？

~~~
1)HashMap的初始化长度为16，并且每次自动扩展或者手动初始化时，长度必须是2个幂；
2)之所以选择16，为了服务于Key映射到index的Hash算法
3)为实现高效的Hash算法，HashMap的发明者采用了位运算的方式；
    公式：index = HashCode(Key) & (Length - 1)  [Length是HashMap的长度]
4)a.计算book的hashcode，结果为十进制的3029737，二进制的101110001110101110 1001。
    b.假定HashMap长度是默认的16，计算Length-1的结果为十进制的15，二进制的1111。
    c.把以上两个结果做与运算，101110001110101110 1001 & 1111 = 1001，十进制是9，所以 index=9。
      可以说，Hash算法最终得到的index结果，完全取决于Key的Hashcode值的最后几位 
5)长度为16或者其他2的幂，Length-1的值，所有的二进制位全为1，这样情况下，index的结果等同于HashCode的
     后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的；
~~~

#### 高并发情况下，为什么HashMap会出现死锁？

~~~
1.HashMap的ReHash
  a.HashMap的容量是有限的。当经过多次元素的插入，是的HashMap达到一定的饱和度时，Key映射位置发生冲突的概率、
    就会提高；这时候就需要扩展长度，也就是要Resize;
  b.影响Resize的因素有两个：
    1)Capacity 
      HashMap的长度，2的幂；
    2)LoadFactor
      HashMap的负载因子，默认值为0.75f;
    3)衡量HashMap是否要进行Resizede条件如下：
      HashMap.size >= Capacity * LoadFactor
  c.ReHash的步骤：
    1)扩容：
      创建一个新的Entry空数组，长度是原数组的2倍；
    2)ReHash
      遍历原Entry数组，把所有的Entry重新Hash到新数组。为什么要重新Hash呢？因为长度扩大以后，
      Hash的规则也随之改变；
  d.并发产生死锁：
    1)并发时在rehash时出现环形链表；
    2)如果查询一个不存在的key时，由于是环形链表，程序将会进入死循环；
~~~

#### Java8当中Hashmap做了哪些优化？

~~~
1.java8在数据存储时融入了红黑树；
2.存储结构：
  数组+链表+红黑树(Jdk1.8增加了红黑树部分)，定量表长度大于8时，转换成红黑树；
3.即使负载因子和Hash算法设计的再合理，也免不了出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。
  于是在Jdk1.8版本中引入了红黑树。当链表长度太长(默认超过8时)，链表就转换成红黑树，领用红黑树快速增删改查的特点提供HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。
4.在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：
 (h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销
5.因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图：
6.这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞；
~~~

~~~java
1 final Node<K,V>[] resize() {
 2     Node<K,V>[] oldTab = table;
 3     int oldCap = (oldTab == null) ? 0 : oldTab.length;
 4     int oldThr = threshold;
 5     int newCap, newThr = 0;
 6     if (oldCap > 0) {
 7         // 超过最大值就不再扩充了，就只好随你碰撞去吧
 8         if (oldCap >= MAXIMUM_CAPACITY) {
 9             threshold = Integer.MAX_VALUE;
10             return oldTab;
11         }
12         // 没超过最大值，就扩充为原来的2倍
13         else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
14                  oldCap >= DEFAULT_INITIAL_CAPACITY)
15             newThr = oldThr << 1; // double threshold
16     }
17     else if (oldThr > 0) // initial capacity was placed in threshold
18         newCap = oldThr;
19     else {               // zero initial threshold signifies using defaults
20         newCap = DEFAULT_INITIAL_CAPACITY;
21         newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
22     }
23     // 计算新的resize上限
24     if (newThr == 0) {
25
26         float ft = (float)newCap * loadFactor;
27         newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
28                   (int)ft : Integer.MAX_VALUE);
29     }
30     threshold = newThr;
31     @SuppressWarnings({"rawtypes"，"unchecked"})
32         Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
33     table = newTab;
34     if (oldTab != null) {
35         // 把每个bucket都移动到新的buckets中
36         for (int j = 0; j < oldCap; ++j) {
37             Node<K,V> e;
38             if ((e = oldTab[j]) != null) {
39                 oldTab[j] = null;
40                 if (e.next == null)
41                     newTab[e.hash & (newCap - 1)] = e;
42                 else if (e instanceof TreeNode)
43                     ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
44                 else { // 链表优化重hash的代码块
45                     Node<K,V> loHead = null, loTail = null;
46                     Node<K,V> hiHead = null, hiTail = null;
47                     Node<K,V> next;
48                     do {
49                         next = e.next;
50                         // 原索引
51                         if ((e.hash & oldCap) == 0) {
52                             if (loTail == null)
53                                 loHead = e;
54                             else
55                                 loTail.next = e;
56                             loTail = e;
57                         }
58                         // 原索引+oldCap
59                         else {
60                             if (hiTail == null)
61                                 hiHead = e;
62                             else
63                                 hiTail.next = e;
64                             hiTail = e;
65                         }
66                     } while ((e = next) != null);
67                     // 原索引放到bucket里
68                     if (loTail != null) {
69                         loTail.next = null;
70                         newTab[j] = loHead;
71                     }
72                     // 原索引+oldCap放到bucket里
73                     if (hiTail != null) {
74                         hiTail.next = null;
75                         newTab[j + oldCap] = hiHead;
76                     }
77                 }
78             }
79         }
80     }
81     return newTab;
82 }
~~~

#### 其他

~~~
(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。
(2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。
(3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。
(4) JDK1.8引入红黑树大程度优化了HashMap的性能。
(5) 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。
~~~

#### 参考

1.什么是HashMap?
https://mp.weixin.qq.com/s?__biz=MzI1MTIzMzI2MA==&mid=2650561632&idx=1&sn=c0baa743db1aae57efcbe0e55dbd1d38&chksm=f1feeae3c68963f572b2dd49ba39f9ab69c2189e5323af125d685ccf426adb0c90af4187205d&scene=21#wechat_redirect

2.高并发下的HashMap

https://mp.weixin.qq.com/s?__biz=MzI1MTIzMzI2MA==&mid=2650561742&idx=1&sn=c99d642c89daa66b157a15c3529092a7&chksm=f1feea4dc689635b31a7ecf859a4fb1834bd4ef1868333bcd352113da127da830442ce31e49c&scene=0#rd

3.重新认识Java8下的HashMap：
  http://www.importnew.com/20386.html

